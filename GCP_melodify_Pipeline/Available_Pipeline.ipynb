{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59dbe53-b72b-40da-89ca-80a9fc4b9277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.dsl import component, pipeline\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "from kfp.dsl import component, pipeline\n",
    "\n",
    "@component(base_image=\"python:3.9\", packages_to_install=[\n",
    "    \"google-cloud-aiplatform==1.60.0\",\n",
    "    \"vertexai==1.43.0\"\n",
    "])\n",
    "def interact_with_gemini_model_once(\n",
    "    initial_prompt: str,\n",
    "    project: str,\n",
    "    region: str,\n",
    "    endpoint_id: str\n",
    ") -> str:\n",
    "    import vertexai\n",
    "    from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "    # Vertex AI 초기화\n",
    "    vertexai.init(project=project, location=region)\n",
    "\n",
    "    # GenerativeModel을 엔드포인트를 통해 로드\n",
    "    model = GenerativeModel(endpoint_id)\n",
    "\n",
    "    # 채팅 시작\n",
    "    chat = model.start_chat()\n",
    "\n",
    "    # 첫 번째 대화에서 응답 생성\n",
    "    response = chat.send_message(initial_prompt)\n",
    "    \n",
    "    # 응답 텍스트를 반환\n",
    "    return response.text\n",
    "\n",
    "@component(base_image=\"python:3.9\", packages_to_install=[\n",
    "    \"google-cloud-aiplatform==1.60.0\",\n",
    "    \"vertexai==1.43.0\"\n",
    "])\n",
    "def interact_with_gemini_model_second(\n",
    "    previous_response_text: str,\n",
    "    user_prompt: str,\n",
    "    project: str,\n",
    "    region: str,\n",
    "    endpoint_id: str\n",
    ") -> str:\n",
    "    import vertexai\n",
    "    from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "    # Vertex AI 초기화\n",
    "    vertexai.init(project=project, location=region)\n",
    "\n",
    "    # GenerativeModel을 엔드포인트를 통해 로드\n",
    "    model = GenerativeModel(endpoint_id)\n",
    "\n",
    "    # 채팅 시작\n",
    "    chat = model.start_chat()\n",
    "\n",
    "    # 이전의 대화 맥락을 유지하며 새로운 프롬프트로 대화 이어나감\n",
    "    combined_prompt = f\"{previous_response_text}\\n\\n{user_prompt}\"\n",
    "    response = chat.send_message(combined_prompt)\n",
    "    \n",
    "    # 응답 텍스트를 반환\n",
    "    return response.text\n",
    "\n",
    "@component(base_image=\"asia-northeast3-docker.pkg.dev/andong-24-team-101/components-image/com-image:latest\")\n",
    "def generate_music(prompt: str, gcs_bucket_name: str, gcs_output_path: str):\n",
    "    \"\"\"\n",
    "    텍스트 프롬프트를 기반으로 음악을 생성하고 GCS 버킷에 WAV 파일로 바로 저장합니다.\n",
    "    \"\"\"\n",
    "    from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "    import torch\n",
    "    import scipy.io.wavfile\n",
    "    from google.cloud import storage\n",
    "    import io\n",
    "    import numpy as np\n",
    "\n",
    "    try:\n",
    "        # 디버깅 로그 추가\n",
    "        print(\"Loading MusicGen model...\")\n",
    "        \n",
    "        processor = AutoProcessor.from_pretrained(\"facebook/musicgen-medium\")\n",
    "        model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-medium\")\n",
    "\n",
    "        # Move model to GPU (cuda) if available\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {device}\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 쿠다 체크\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA is available. Number of GPUs: {torch.cuda.device_count()}\")\n",
    "            print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"CUDA is not available.\")\n",
    "\n",
    "        # Process the prompt and move inputs to the appropriate device\n",
    "        inputs = processor(text=[prompt], padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Generate audio\n",
    "        with torch.no_grad():\n",
    "            audio_values = model.generate(**inputs, guidance_scale=2, max_new_tokens=800)\n",
    "\n",
    "        # Set sampling rate from model configuration\n",
    "        sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "\n",
    "        # Convert audio tensor to CPU and to numpy array\n",
    "        audio_data = audio_values[0, 0].cpu().numpy()\n",
    "\n",
    "        # Convert numpy array to WAV format in memory using BytesIO\n",
    "        wav_io = io.BytesIO()\n",
    "        scipy.io.wavfile.write(wav_io, rate=sampling_rate, data=audio_data.astype(np.float32))\n",
    "\n",
    "        # Seek to the beginning of the BytesIO object to prepare for upload\n",
    "        wav_io.seek(0)\n",
    "\n",
    "        # Initialize the Google Cloud Storage client\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        # Upload the in-memory WAV file to the specified GCS bucket\n",
    "        bucket = storage_client.bucket(gcs_bucket_name)\n",
    "        blob = bucket.blob(gcs_output_path)\n",
    "        \n",
    "        # Upload the WAV file directly from memory\n",
    "        blob.upload_from_file(wav_io, content_type=\"audio/wav\")\n",
    "\n",
    "        print(f\"File uploaded to {gcs_bucket_name}/{gcs_output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during generate_music: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@pipeline(name=\"music-generation-pipeline\", description=\"A pipeline to generate music based on two rounds of conversation with Gemini model.\")\n",
    "def music_generation_pipeline(\n",
    "    initial_prompt: str,\n",
    "    user_prompt: str,\n",
    "    endpoint_id: str,\n",
    "    project: str,\n",
    "    region: str,\n",
    "    gcs_bucket_name: str,\n",
    "    gcs_output_path: str\n",
    "):\n",
    "    # 첫 번째 대화 실행\n",
    "    first_response = interact_with_gemini_model_once(\n",
    "        initial_prompt=initial_prompt,\n",
    "        project=project,\n",
    "        region=region,\n",
    "        endpoint_id=endpoint_id\n",
    "    ).set_caching_options(True)  # 캐싱 활성화\n",
    "\n",
    "    # 두 번째 대화 실행\n",
    "    second_response = interact_with_gemini_model_second(\n",
    "        previous_response_text=first_response.output,\n",
    "        user_prompt=user_prompt,\n",
    "        project=project,\n",
    "        region=region,\n",
    "        endpoint_id=endpoint_id\n",
    "    ).set_caching_options(True)  # 캐싱 활성화\n",
    "\n",
    "    # 생성된 텍스트로 음악 생성 및 바로 GCS에 저장\n",
    "    generate_music_task = generate_music(\n",
    "        prompt=second_response.output,\n",
    "        gcs_bucket_name=gcs_bucket_name,\n",
    "        gcs_output_path=gcs_output_path\n",
    "    ).set_caching_options(True)  # 캐싱 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d618e1-1729-405b-9702-d733ace50a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-northeast3/pipelines/runs/music-generation-pipeline-20240827213328?project=535442247184\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/535442247184/locations/asia-northeast3/pipelineJobs/music-generation-pipeline-20240827213328\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud.aiplatform.pipeline_jobs import PipelineJob\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 파이프라인을 JSON 파일로 컴파일\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=music_generation_pipeline,\n",
    "        package_path=\"music_generation_pipeline.json\"\n",
    "    )\n",
    "\n",
    "    # Vertex AI 초기화\n",
    "    aiplatform.init(project='andong-24-team-101', location='asia-northeast3')\n",
    "\n",
    "    # 파이프라인 제출\n",
    "    pipeline_job = PipelineJob(\n",
    "        display_name=\"music-generation-pipeline\",\n",
    "        template_path=\"music_generation_pipeline.json\",\n",
    "        pipeline_root=\"gs://test_music_team_101/test_pipeline\",\n",
    "        parameter_values={\n",
    "            \"initial_prompt\": \"Input Description of desire for musical expression!\",\n",
    "            \"user_prompt\": \"beautiful woman is looking at Eiffel Tower\",  # 웹에서 이미지 분석해서 생성한 텍스트 위치\n",
    "            \"endpoint_id\": \"projects/535442247184/locations/asia-northeast3/endpoints/7748060528844472320\",\n",
    "            \"project\": \"andong-24-team-101\",\n",
    "            \"region\": \"asia-northeast3\",\n",
    "            \"gcs_bucket_name\": \"test_music_team_101\",  # GCS 버킷 이름\n",
    "            \"gcs_output_path\": \"test_wav/advanced_New.wav\"  # 버킷 내 파일을 저장할 경로\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 파이프라인을 실행하여 제출 (동기식)\n",
    "    pipeline_job.run(sync=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662fcbf-8c19-46da-882a-ce7d0b234d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu118.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu118:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
